Exercise 2.1 
- Suppose that the performance measure is concerned with just the first T time steps of
the environment and ignores everything thereafter. Show that a rational agentâ€™s action may
depend not just on the state of the environment but also on the time step it has reached.

For an agent to be rational it depends on four things:
- performance measure to define success
- prior knowledge of the environment
- actions that can be performed
- percept of sequence to date

With these four things we can see that each step that a rational argent executes there is a process of understanding that must take place. If the performance successes are not defined properly the agent my end up stuck on a step indefinitely.

Exercise 2.5 
- Define in your own words the following terms: agent, agent function, agent program,
rationality, autonomy, reflex agent, model-based agent, goal-based agent, utility-based agent,
learning agent.

An agent is a set of sensors and actuators to perceive the environment.

An agent function is an algorithm that maps the environment to be perceived.

An agent program is code that executes agent functions.

Rationality is a set of information and data that can be used to take actions on an environment. 

Autonomy is when an agent uses its own perceptions to act on an environment. 

Reflex agents act on the basis of current information, they ignore history.

Model-based agents use a set of historical data and/or information to perceive the environment. 

Goal-based agents build upon the state of an environment and have a goal added to the environment. 

Utility-based agents go one step further than goal-based agents by adding a comparison between the goal and non-goal state. This measures that "amount of goal" the agent acts upon.

A learning agent is the ideal state for state of the art AI. A learning agent operates in an unknown environment and becomes more competent as it acts upon the environment. 